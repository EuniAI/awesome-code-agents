<div align="center">
  <h1>ðŸ¤– Awesome Code Agents</h1>

  <!-- Badges -->
  <a href="https://awesome.re">
    <img src="https://awesome.re/badge.svg" alt="Awesome">
  </a>
  <a href="https://img.shields.io/badge/PRs-Welcome-red">
    <img src="https://img.shields.io/badge/PRs-Welcome-red" alt="PRs Welcome">
  </a>
  <a href="https://img.shields.io/github/last-commit/EuniAI/awesome-code-agents?color=green">
    <img src="https://img.shields.io/github/last-commit/EuniAI/awesome-code-agents?color=green" alt="Last Commit">
  </a>
</div>

<!-- Optional teaser -->
<!--
<p align="center">
  <img src="assets/teaser.png" width="520px"/>
</p>
-->
<p align="center">
  A curated list of <b>products, benchmarks, and research papers</b> on <b>Code Agents</b>.
</p>

---

## Quick Navigation

- [ðŸš€ Products & Tools](#-products--tools)
- [ðŸ“Š Benchmarks & Leaderboards](#-benchmarks--leaderboards)
- [ðŸ“š Papers](#-papers)
  * [ðŸ”Ž Surveys](#-surveys)
  * [ðŸ— Environment Building](#-environment-building)
  * [ðŸ” Issue Reproduction](#-issue-reproduction)
  * [ðŸŽ¯ Issue Localization](#-issue-localization)
  * [ðŸ›  Issue Resolution](#-issue-resolution)
  * [â“ Q&A](#-qa)
  * [ðŸ” PR & Review](#-pr--review)
  * [âœ¨ Feature Development](#-feature-development)
  * [ðŸ”„ Git Management](#-git-management)
  * [âš¡ Performance Optimization](#-performance-optimization)
  * [ðŸŒ Website Generation](#-website-generation)
  * [ðŸ‘©â€ðŸ’» Machine Learning Engineering](#-machine-learning-engineering)
  * [SQL Issue Resolution](#sql-issue-resolution)
  * [ðŸ•¹ï¸ Unified Agents](#-unified-agents)
  * [ðŸŽ“ Post-Training](#-post-training)
  * [âš– Test-time Scaling](#-test-time-scaling)
  * [ðŸ–¼ Multimodal](#-multimodal)
  * [ðŸ§¬ Data Synthesis](#-data-synthesis)
  * [ðŸ“Š Empirical Studies](#-empirical-studies)  
- [ðŸ¤ Contributing](#-contributing)
- [ðŸŒŸ Star History](#-star-history)
- [ðŸ™ Acknowledgements](#-acknowledgements)

---

## ðŸš€ Products & Tools
> Leading agentic systems, frameworks, and platforms for automated software development.

<!-- START PAPERS:products -->
- **Claude Code.**  
  _Anthropic._ 2025.  
  [![GitHub Stars](https://img.shields.io/github/stars/anthropics/claude-code?style=for-the-badge&logo=github&label=GitHub&color=black)](https://github.com/anthropics/claude-code) [![Website](https://img.shields.io/website?url=https://claude.com/product/claude-code&up_message=CLAUDE-CODE&up_color=blue&down_message=CLAUDE-CODE&down_color=blue&style=for-the-badge)](https://claude.com/product/claude-code)

- **Codex.**  
  _OpenAI._ 2025.  
  [![GitHub Stars](https://img.shields.io/github/stars/openai/codex?style=for-the-badge&logo=github&label=GitHub&color=black)](https://github.com/openai/codex) [![Website](https://img.shields.io/website?url=https://openai.com/codex/&up_message=CODEX&up_color=blue&down_message=CODEX&down_color=blue&style=for-the-badge)](https://openai.com/codex/)

- **Lovable.**  
  _Lovable._ 2024.  
  [![Website](https://img.shields.io/website?url=https://lovable.dev/&up_message=LOVABLE&up_color=blue&down_message=LOVABLE&down_color=blue&style=for-the-badge)](https://lovable.dev/)

- **Devin.**  
  _Cognition AI._ 2024.  
  [![Website](https://img.shields.io/website?url=https://devin.ai/&up_message=DEVIN.AI&up_color=blue&down_message=DEVIN.AI&down_color=blue&style=for-the-badge)](https://devin.ai/)

- **OpenHands.**  
  _All Hands AI._ 2024.  
  [![Paper](https://img.shields.io/badge/paper-A42C25?style=for-the-badge&logo=arxiv&logoColor=white)](https://arxiv.org/abs/2407.16741) [![GitHub Stars](https://img.shields.io/github/stars/All-Hands-AI/OpenHands?style=for-the-badge&logo=github&label=GitHub&color=black)](https://github.com/All-Hands-AI/OpenHands) [![Website](https://img.shields.io/website?url=https://www.all-hands.dev/&up_message=ALL-HANDS&up_color=blue&down_message=ALL-HANDS&down_color=blue&style=for-the-badge)](https://www.all-hands.dev/)

- **Aider.**  
  _Aider AI._ 2025.  
  [![GitHub Stars](https://img.shields.io/github/stars/Aider-AI/aider?style=for-the-badge&logo=github&label=GitHub&color=black)](https://github.com/Aider-AI/aider) [![Website](https://img.shields.io/website?url=https://aider.chat/&up_message=AIDER.CHAT&up_color=blue&down_message=AIDER.CHAT&down_color=blue&style=for-the-badge)](https://aider.chat/)

- **Prometheus.**  
  _EuniAI._ 2025.  
  [![Paper](https://img.shields.io/badge/paper-A42C25?style=for-the-badge&logo=arxiv&logoColor=white)](https://arxiv.org/abs/2507.19942) [![GitHub Stars](https://img.shields.io/github/stars/EuniAI/Prometheus?style=for-the-badge&logo=github&label=GitHub&color=black)](https://github.com/EuniAI/Prometheus) [![Website](https://img.shields.io/website?url=https://euni.ai/&up_message=EUNI.AI&up_color=blue&down_message=EUNI.AI&down_color=blue&style=for-the-badge)](https://euni.ai/)

- **SWE-agent.**  
  _Princeton University._ 2024.  
  [![Paper](https://img.shields.io/badge/paper-A42C25?style=for-the-badge&logo=arxiv&logoColor=white)](https://arxiv.org/abs/2405.15793) [![GitHub Stars](https://img.shields.io/github/stars/SWE-agent/SWE-agent?style=for-the-badge&logo=github&label=GitHub&color=black)](https://github.com/SWE-agent/SWE-agent) [![Website](https://img.shields.io/website?url=https://swe-agent.com/&up_message=SWE-AGENT&up_color=blue&down_message=SWE-AGENT&down_color=blue&style=for-the-badge)](https://swe-agent.com/)

- **Open Lovable.**  
  _Firecrawl._ 2025.  
  [![GitHub Stars](https://img.shields.io/github/stars/firecrawl/open-lovable?style=for-the-badge&logo=github&label=GitHub&color=black)](https://github.com/firecrawl/open-lovable) [![Website](https://img.shields.io/website?url=https://open-lovable.com/&up_message=OPEN-LOVABLE&up_color=blue&down_message=OPEN-LOVABLE&down_color=blue&style=for-the-badge)](https://open-lovable.com/)

- **PR-Agent & Qodo Merge.**  
  _Qodo._ 2024.  
  [![GitHub Stars](https://img.shields.io/github/stars/qodo-ai/pr-agent?style=for-the-badge&logo=github&label=GitHub&color=black)](https://github.com/qodo-ai/pr-agent) [![Website](https://img.shields.io/website?url=https://www.qodo.ai/&up_message=QODO.AI&up_color=blue&down_message=QODO.AI&down_color=blue&style=for-the-badge)](https://www.qodo.ai/)

- **Lingma SWE-GPT.**  
  _Tongyi / Alibaba._ 2025.  
  [![Paper](https://img.shields.io/badge/paper-A42C25?style=for-the-badge&logo=arxiv&logoColor=white)](https://arxiv.org/abs/2411.00622) [![GitHub Stars](https://img.shields.io/github/stars/LingmaTongyi/Lingma-SWE-GPT?style=for-the-badge&logo=github&label=GitHub&color=black)](https://github.com/LingmaTongyi/Lingma-SWE-GPT)

- **Agentless.**  
  _University of Illinois Urbana-Champaign._ 2024.  
  [![Paper](https://img.shields.io/badge/paper-A42C25?style=for-the-badge&logo=arxiv&logoColor=white)](https://arxiv.org/abs/2407.01489) [![GitHub Stars](https://img.shields.io/github/stars/OpenAutoCoder/Agentless?style=for-the-badge&logo=github&label=GitHub&color=black)](https://github.com/OpenAutoCoder/Agentless)

- **AutoCodeRover.**  
  _National University of Singapore (product now acquired by Sonar)._ 2024.  
  [![Paper](https://img.shields.io/badge/paper-A42C25?style=for-the-badge&logo=arxiv&logoColor=white)](https://arxiv.org/abs/2404.05427) [![GitHub Stars](https://img.shields.io/github/stars/AutoCodeRoverSG/auto-code-rover?style=for-the-badge&logo=github&label=GitHub&color=black)](https://github.com/AutoCodeRoverSG/auto-code-rover) [![Website](https://img.shields.io/website?url=https://autocoderover.dev/&up_message=AUTOCODEROVER&up_color=blue&down_message=AUTOCODEROVER&down_color=blue&style=for-the-badge)](https://autocoderover.dev/)

- **OpenCode.**  
  _SST._ 2025.  
  [![GitHub Stars](https://img.shields.io/github/stars/sst/opencode?style=for-the-badge&logo=github&label=GitHub&color=black)](https://github.com/sst/opencode) [![Website](https://img.shields.io/website?url=https://opencode.ai/&up_message=OPENCODE.AI&up_color=blue&down_message=OPENCODE.AI&down_color=blue&style=for-the-badge)](https://opencode.ai/)

- **Jules.**  
  _Google._ 2025.  
  [![Website](https://img.shields.io/website?url=https://jules.google/&up_message=JULES.GOOGLE&up_color=blue&down_message=JULES.GOOGLE&down_color=blue&style=for-the-badge)](https://jules.google/)

- **Droids.**  
  _Factory._ 2025.  
  [![Website](https://img.shields.io/website?url=https://factory.ai/&up_message=FACTORY.AI&up_color=blue&down_message=FACTORY.AI&down_color=blue&style=for-the-badge)](https://factory.ai/)

- **KAT-Coder.**  
  _Kwaipilot / Kuaishou._ 2025.  
  [![Website](https://img.shields.io/website?url=https://kwaipilot.github.io/KAT-Coder/&up_message=KAT-CODER&up_color=blue&down_message=KAT-CODER&down_color=blue&style=for-the-badge)](https://kwaipilot.github.io/KAT-Coder/)

- **Kiro.**  
  _AWS._ 2025.  
  [![GitHub Stars](https://img.shields.io/github/stars/kirodotdev/Kiro?style=for-the-badge&logo=github&label=GitHub&color=black)](https://github.com/kirodotdev/Kiro) [![Website](https://img.shields.io/website?url=https://kiro.dev/&up_message=KIRO&up_color=blue&down_message=KIRO&down_color=blue&style=for-the-badge)](https://kiro.dev/)

- **Essential.**  
  _Nothing._ 2025.  
  [![Website](https://img.shields.io/website?url=https://www.essential.com/&up_message=ESSENTIAL&up_color=blue&down_message=ESSENTIAL&down_color=blue&style=for-the-badge)](https://www.essential.com/)

- **Anything.**  
  _Anything._ 2025.  
  [![Website](https://img.shields.io/website?url=https://www.createanything.com/&up_message=CREATEANYTHING&up_color=blue&down_message=CREATEANYTHING&down_color=blue&style=for-the-badge)](https://www.createanything.com/)
<!-- END PAPERS:products -->
---

## ðŸ“Š Benchmarks & Leaderboards
> Standardized evaluation suites for code agents.

<!-- START PAPERS:benchmarks -->
- **Terminal-Bench: A Benchmark for AI Agents in Terminal Environments.**  
  _The Terminal-Bench Team._ 2025.  
  [![GitHub Stars](https://img.shields.io/github/stars/laude-institute/terminal-bench?style=for-the-badge&logo=github&label=GitHub&color=black)](https://github.com/laude-institute/terminal-bench) [![Website](https://img.shields.io/website?url=https://www.tbench.ai/&up_message=TBENCH.AI&up_color=blue&down_message=TBENCH.AI&down_color=blue&style=for-the-badge)](https://www.tbench.ai/)

- **SWE-Bench Pro: Can AI Agents Solve Long-Horizon Software Engineering Tasks?**  
  _Xiang Deng, Jeff Da, Edwin Pan, Yannis Yiming He, Charles Ide, Kanak Garg, Niklas Lauffer, Andrew Park, Nitin Pasari, Chetan Rane, Karmini Sampath, Maya Krishnan, Srivatsa Kundurthy, Sean Hendryx, Zifan Wang, Chen Bo Calvin Zhang, Noah Jacobson, Bing Liu, Brad Kenstler._ arXiv 2025.  
  [![Paper](https://img.shields.io/badge/paper-A42C25?style=for-the-badge&logo=arxiv&logoColor=white)](https://arxiv.org/abs/2509.16941) [![GitHub Stars](https://img.shields.io/github/stars/scaleapi/SWE-bench_Pro-os?style=for-the-badge&logo=github&label=GitHub&color=black)](https://github.com/scaleapi/SWE-bench_Pro-os) [![Website](https://img.shields.io/website?url=https://scale.com/leaderboard/swe_bench_pro_public&up_message=SWE-BENCH-PRO-PUBLIC&up_color=blue&down_message=SWE-BENCH-PRO-PUBLIC&down_color=blue&style=for-the-badge)](https://scale.com/leaderboard/swe_bench_pro_public)

- **SWE-PolyBench: A multi-language benchmark for repository level evaluation of coding agents.**  
  _Muhammad Shihab Rashid, Christian Bock, Yuan Zhuang, Alexander Buchholz, Tim Esler, Simon Valentin, Luca Franceschi, Martin Wistuba, Prabhu Teja Sivaprasad, Woo Jung Kim, Anoop Deoras, Giovanni Zappella, Laurent Callot._ arXiv 2025.  
  [![Paper](https://img.shields.io/badge/paper-A42C25?style=for-the-badge&logo=arxiv&logoColor=white)](https://arxiv.org/abs/2504.08703) [![GitHub Stars](https://img.shields.io/github/stars/amazon-science/SWE-PolyBench?style=for-the-badge&logo=github&label=GitHub&color=black)](https://github.com/amazon-science/SWE-PolyBench) [![Website](https://img.shields.io/website?url=https://amazon-science.github.io/SWE-PolyBench/&up_message=SWE-POLYBENCH&up_color=blue&down_message=SWE-POLYBENCH&down_color=blue&style=for-the-badge)](https://amazon-science.github.io/SWE-PolyBench/)

- **SWE-SQL: Illuminating LLM Pathways to Solve User SQL Issues in Real-World Applications.**  
  _Jinyang Li, Xiaolong Li, Ge Qu, Per Jacobsson, Bowen Qin, Binyuan Hui, Shuzheng Si, Nan Huo, Xiaohan Xu, Yue Zhang, Ziwei Tang, Yuanshuai Li, Florensia Widjaja, Xintong Zhu, Feige Zhou, Yongfeng Huang, Yannis Papakonstantinou, Fatma Ozcan, Chenhao Ma, Reynold Cheng._ arXiv 2025.  
  [![Paper](https://img.shields.io/badge/paper-A42C25?style=for-the-badge&logo=arxiv&logoColor=white)](https://arxiv.org/abs/2506.18951) [![GitHub Stars](https://img.shields.io/github/stars/bird-bench/BIRD-CRITIC-1?style=for-the-badge&logo=github&label=GitHub&color=black)](https://github.com/bird-bench/BIRD-CRITIC-1) [![Website](https://img.shields.io/website?url=https://bird-critic.github.io/&up_message=BIRD-CRITIC&up_color=blue&down_message=BIRD-CRITIC&down_color=blue&style=for-the-badge)](https://bird-critic.github.io/)

- **Multi-SWE-bench: A Multilingual Benchmark for Issue Resolving.**  
  _Daoguang Zan, Zhirong Huang, Wei Liu, Hanwu Chen, Linhao Zhang, Shulin Xin, Lu Chen, Qi Liu, Xiaojian Zhong, Aoyan Li, Siyao Liu, Yongsheng Xiao, Liangqiang Chen, Yuyu Zhang, Jing Su, Tianyu Liu, Rui Long, Kai Shen, Liang Xiang._ arXiv 2025.  
  [![Paper](https://img.shields.io/badge/paper-A42C25?style=for-the-badge&logo=arxiv&logoColor=white)](https://arxiv.org/abs/2504.02605) [![GitHub Stars](https://img.shields.io/github/stars/multi-swe-bench/multi-swe-bench?style=for-the-badge&logo=github&label=GitHub&color=black)](https://github.com/multi-swe-bench/multi-swe-bench) [![Website](https://img.shields.io/website?url=https://multi-swe-bench.github.io/&up_message=MULTI-SWE-BENCH&up_color=blue&down_message=MULTI-SWE-BENCH&down_color=blue&style=for-the-badge)](https://multi-swe-bench.github.io/)

- **SWE-Effi: Re-Evaluating Software AI Agent System Effectiveness Under Resource Constraints.**  
  _Zhiyu Fan, Kirill Vasilevski, Dayi Lin, Boyuan Chen, Yihao Chen, Zhiqing Zhong, Jie M. Zhang, Pinjia He, Ahmed E. Hassan._ arXiv 2025.  
  [![Paper](https://img.shields.io/badge/paper-A42C25?style=for-the-badge&logo=arxiv&logoColor=white)](https://arxiv.org/abs/2509.09853) [![Website](https://img.shields.io/website?url=https://github.com/Centre-for-Software-Excellence/SWE-Effi&up_message=SWE-EFFI&up_color=blue&down_message=SWE-EFFI&down_color=blue&style=for-the-badge)](https://github.com/Centre-for-Software-Excellence/SWE-Effi)

- **SEC-bench: Automated Benchmarking of LLM Agents on Real-World Software Security Tasks.**  
  _Hwiwon Lee, Ziqi Zhang, Hanxiao Lu, Lingming Zhang._ arXiv 2025.  
  [![Paper](https://img.shields.io/badge/paper-A42C25?style=for-the-badge&logo=arxiv&logoColor=white)](https://arxiv.org/abs/2506.11791) [![GitHub Stars](https://img.shields.io/github/stars/SEC-bench/SEC-bench?style=for-the-badge&logo=github&label=GitHub&color=black)](https://github.com/SEC-bench/SEC-bench) [![Website](https://img.shields.io/website?url=https://sec-bench.github.io/&up_message=SEC-BENCH&up_color=blue&down_message=SEC-BENCH&down_color=blue&style=for-the-badge)](https://sec-bench.github.io/)

- **SecureAgentBench: Benchmarking Secure Code Generation under Realistic Vulnerability Scenarios.**  
  _Junkai Chen, Huihui Huang, Yunbo Lyu, Junwen An, Jieke Shi, Chengran Yang, Ting Zhang, Haoye Tian, Yikun Li, Zhenhao Li, Xin Zhou, Xing Hu, David Lo._ arXiv 2025.  
  [![Paper](https://img.shields.io/badge/paper-A42C25?style=for-the-badge&logo=arxiv&logoColor=white)](https://arxiv.org/abs/2509.22097) [![GitHub Stars](https://img.shields.io/github/stars/iCSawyer/SecureAgentBench?style=for-the-badge&logo=github&label=GitHub&color=black)](https://github.com/iCSawyer/SecureAgentBench)

- **SWE-MERA: A Dynamic Benchmark for Agenticly Evaluating Large Language Models on Software Engineering Tasks.**  
  _Pavel Adamenko, Mikhail Ivanov, Aidar Valeev, Rodion Levichev, Pavel Zadorozhny, Ivan Lopatin, Dmitry Babayev, Alena Fenogenova, Valentin Malykh._ arXiv 2025.  
  [![Paper](https://img.shields.io/badge/paper-A42C25?style=for-the-badge&logo=arxiv&logoColor=white)](https://arxiv.org/abs/2507.11059) [![GitHub Stars](https://img.shields.io/github/stars/MERA-Evaluation/repotest?style=for-the-badge&logo=github&label=GitHub&color=black)](https://github.com/MERA-Evaluation/repotest) [![Website](https://img.shields.io/website?url=https://mera-evaluation.github.io/demo-swe-mera/&up_message=DEMO-SWE-MERA&up_color=blue&down_message=DEMO-SWE-MERA&down_color=blue&style=for-the-badge)](https://mera-evaluation.github.io/demo-swe-mera/)

- **Auto-SWE-Bench: A Framework for the Scalable Generation of Software Engineering Benchmark from Open-Source Repositories.**  
  _Anonymous Authors._ 2025.  
  [![Paper](https://img.shields.io/badge/paper-A42C25?style=for-the-badge&logo=arxiv&logoColor=white)](https://openreview.net/forum?id=Gxw1EDSm9S)

- **SWE-bench Goes Live!**  
  _Linghao Zhang, Shilin He, Chaoyun Zhang, Yu Kang, Bowen Li, Chengxing Xie, Junhao Wang, Maoquan Wang, Yufan Huang, Shengyu Fu, Elsie Nallipogu, Qingwei Lin, Yingnong Dang, Saravan Rajmohan, Dongmei Zhang._ NeurIPS 2025 Datasets & Benchmarks Track.  
  [![Paper](https://img.shields.io/badge/paper-A42C25?style=for-the-badge&logo=arxiv&logoColor=white)](https://arxiv.org/abs/2505.23419) [![GitHub Stars](https://img.shields.io/github/stars/microsoft/SWE-bench-Live?style=for-the-badge&logo=github&label=GitHub&color=black)](https://github.com/microsoft/SWE-bench-Live) [![Website](https://img.shields.io/website?url=https://swe-bench-live.github.io/&up_message=SWE-BENCH-LIVE&up_color=blue&down_message=SWE-BENCH-LIVE&down_color=blue&style=for-the-badge)](https://swe-bench-live.github.io/)

- **SWE-Lancer: Can Frontier LLMs Earn $1 Million from Real-World Freelance Software Engineering?**  
  _Samuel Miserendino, Michele Wang, Tejal Patwardhan, Johannes Heidecke._ ICML 2025.  
  [![Paper](https://img.shields.io/badge/paper-A42C25?style=for-the-badge&logo=arxiv&logoColor=white)](https://arxiv.org/abs/2502.12115) [![GitHub Stars](https://img.shields.io/github/stars/openai/frontier-evals?style=for-the-badge&logo=github&label=GitHub&color=black)](https://github.com/openai/frontier-evals/tree/main/project/swelancer) [![Website](https://img.shields.io/website?url=https://openai.com/index/swe-lancer/&up_message=SWE-LANCER&up_color=blue&down_message=SWE-LANCER&down_color=blue&style=for-the-badge)](https://openai.com/index/swe-lancer/)

- **CVE-Bench: A Benchmark for AI Agentsâ€™ Ability to Exploit Real-World Web Application Vulnerabilities.**  
  _Yuxuan Zhu, Antony Kellermann, Dylan Bowman, Philip Li, Akul Gupta, Adarsh Danda, Richard Fang, Conner Jensen, Eric Ihli, Jason Benn, Jet Geronimo, Avi Dhir, Sudhit Rao, Kaicheng Yu, Twm Stone, Daniel Kang._ ICML 2025.  
  [![Paper](https://img.shields.io/badge/paper-A42C25?style=for-the-badge&logo=arxiv&logoColor=white)](https://arxiv.org/abs/2503.17332) [![GitHub Stars](https://img.shields.io/github/stars/uiuc-kang-lab/cve-bench?style=for-the-badge&logo=github&label=GitHub&color=black)](https://github.com/uiuc-kang-lab/cve-bench)

- **CVE-Bench: Benchmarking LLM-based Software Engineering Agentâ€™s Ability to Repair Real-World CVE Vulnerabilities.**  
  _Peiran Wang, Xiaogeng Liu, Chaowei Xiao._ NAACL 2025.  
  [![Paper](https://img.shields.io/badge/paper-A42C25?style=for-the-badge&logo=arxiv&logoColor=white)](https://aclanthology.org/2025.naacl-long.212/)

- **EnvBench: A Benchmark for Automated Environment Setup.**  
  _Aleksandra Eliseeva, Alexander Kovrigin, Ilia Kholkin, Egor Bogomolov, Yaroslav Zharov._ ICLR 2025 Workshop.  
  [![Paper](https://img.shields.io/badge/paper-A42C25?style=for-the-badge&logo=arxiv&logoColor=white)](https://arxiv.org/abs/2503.14443) [![GitHub Stars](https://img.shields.io/github/stars/JetBrains-Research/EnvBench?style=for-the-badge&logo=github&label=GitHub&color=black)](https://github.com/JetBrains-Research/EnvBench) [![Website](https://img.shields.io/website?url=https://huggingface.co/datasets/JetBrains-Research/EnvBench&up_message=ENVBENCH&up_color=blue&down_message=ENVBENCH&down_color=blue&style=for-the-badge)](https://huggingface.co/datasets/JetBrains-Research/EnvBench)

- **OmniGIRL: A Multilingual and Multimodal Benchmark for GitHub Issue Resolution.**  
  _Lianghong Guo, Wei Tao, Runhan Jiang, Yanlin Wang, Jiachi Chen, Xilin Liu, Yuchi Ma, Mingzhi Mao, Hongyu Zhang, Zibin Zheng._ ISSTA 2025.  
  [![Paper](https://img.shields.io/badge/paper-A42C25?style=for-the-badge&logo=arxiv&logoColor=white)](https://arxiv.org/abs/2505.04606) [![GitHub Stars](https://img.shields.io/github/stars/DeepSoftwareAnalytics/OmniGIRL?style=for-the-badge&logo=github&label=GitHub&color=black)](https://github.com/DeepSoftwareAnalytics/OmniGIRL) [![Website](https://img.shields.io/website?url=https://deepsoftwareanalytics.github.io/omnigirl_leaderboard.html&up_message=OMNIGIRL-LEADERBOARD&up_color=blue&down_message=OMNIGIRL-LEADERBOARD&down_color=blue&style=for-the-badge)](https://deepsoftwareanalytics.github.io/omnigirl_leaderboard.html)

- **SWE-bench: Can Language Models Resolve Real-World GitHub Issues?**  
  _Carlos E. Jimenez, John Yang, Alexander Wettig, Shunyu Yao, Kexin Pei, Ofir Press, Karthik Narasimhan._ ICLR 2024.  
  [![Paper](https://img.shields.io/badge/paper-A42C25?style=for-the-badge&logo=arxiv&logoColor=white)](https://arxiv.org/abs/2310.06770) [![GitHub Stars](https://img.shields.io/github/stars/SWE-bench/SWE-bench?style=for-the-badge&logo=github&label=GitHub&color=black)](https://github.com/SWE-bench/SWE-bench) [![Website](https://img.shields.io/website?url=https://www.swebench.com/&up_message=SWEBENCH&up_color=blue&down_message=SWEBENCH&down_color=blue&style=for-the-badge)](https://www.swebench.com/)
<!-- END PAPERS:benchmarks -->

---

## ðŸ“š Papers
> 

### ðŸ”Ž Surveys
> 

<!-- START PAPERS:surveys -->
- **A Comprehensive Survey on Benchmarks and Solutions in Software Engineering of LLM-Empowered Agentic System.**  
  _Jiale Guo, Suizhi Huang, Mei Li, Dong Huang, Xingsheng Chen, Regina Zhang, Zhijiang Guo, Han Yu, Siu-Ming Yiu, Christian Jensen, Pietro Lio, Kwok-Yan Lam._ arXiv 2025.  
  [![Paper](https://img.shields.io/badge/paper-A42C25?style=for-the-badge&logo=arxiv&logoColor=white)](https://arxiv.org/abs/2510.09721) [![GitHub Stars](https://img.shields.io/github/stars/lisaGuojl/LLM-Agent-SE-Survey?style=for-the-badge&logo=github&label=GitHub&color=black)](https://github.com/lisaGuojl/LLM-Agent-SE-Survey)

- **How Does LLM Reasoning Work for Code? A Survey and a Call to Action.**  
  _Ira Ceka, Saurabh Pujar, Irene Manotas, Gail Kaiser, Baishakhi Ray, Shyam Ramji._ arXiv 2025.  
  [![Paper](https://img.shields.io/badge/paper-A42C25?style=for-the-badge&logo=arxiv&logoColor=white)](https://arxiv.org/abs/2506.13932)

- **The Rise of AI Teammates in Software Engineering (SE) 3.0: How Autonomous Coding Agents Are Reshaping Software Engineering.**  
  _Hao Li, Haoxiang Zhang, Ahmed E. Hassan._ arXiv 2025.  
  [![Paper](https://img.shields.io/badge/paper-A42C25?style=for-the-badge&logo=arxiv&logoColor=white)](https://arxiv.org/abs/2507.15003) [![GitHub Stars](https://img.shields.io/github/stars/SAILResearch/AI_Teammates_in_SE3?style=for-the-badge&logo=github&label=GitHub&color=black)](https://github.com/SAILResearch/AI_Teammates_in_SE3)

- **Agentic Software Engineering: Foundational Pillars and a Research Roadmap.**  
  _Ahmed E. Hassan, Hao Li, Dayi Lin, Bram Adams, Tse-Hsun Chen, Yutaro Kashiwa, Dong Qiu._ arXiv 2025.  
  [![Paper](https://img.shields.io/badge/paper-A42C25?style=for-the-badge&logo=arxiv&logoColor=white)](https://arxiv.org/abs/2509.06216)
<!-- END PAPERS:surveys -->

- Agents in Software Engineering: Survey, Landscape, and Vision
- **OS Agents Survey** (Dec 2024) â€” survey on MLLM-based OS/IDE agents.  

---

### ðŸ›  Issue Resolution
> Automated bug fixing, patch generation, repair techniques.

<!-- START PAPERS:issue_resolution -->
- **Prometheus: Unified Knowledge Graphs for Issue Resolution in Multilingual Codebases.**  
  _Zimin Chen, Yue Pan, Siyu Lu, Jiayi Xu, Claire Le Goues, Martin Monperrus, He Ye._ arXiv 2025.  
  [![Paper](https://img.shields.io/badge/paper-A42C25?style=for-the-badge&logo=arxiv&logoColor=white)](https://arxiv.org/abs/2507.19942) [![GitHub Stars](https://img.shields.io/github/stars/EuniAI/Prometheus?style=for-the-badge&logo=github&label=GitHub&color=black)](https://github.com/EuniAI/Prometheus) [![Website](https://img.shields.io/website?url=https://euni.ai/&up_message=EUNI.AI&up_color=blue&down_message=EUNI.AI&down_color=blue&style=for-the-badge)](https://euni.ai/)

- **Terminal-Bench: A Benchmark for AI Agents in Terminal Environments.**  
  _The Terminal-Bench Team._ 2025.  
  [![GitHub Stars](https://img.shields.io/github/stars/laude-institute/terminal-bench?style=for-the-badge&logo=github&label=GitHub&color=black)](https://github.com/laude-institute/terminal-bench) [![Website](https://img.shields.io/website?url=https://www.tbench.ai/&up_message=TBENCH.AI&up_color=blue&down_message=TBENCH.AI&down_color=blue&style=for-the-badge)](https://www.tbench.ai/)

- **SWE-Bench Pro: Can AI Agents Solve Long-Horizon Software Engineering Tasks?**  
  _Xiang Deng, Jeff Da, Edwin Pan, Yannis Yiming He, Charles Ide, Kanak Garg, Niklas Lauffer, Andrew Park, Nitin Pasari, Chetan Rane, Karmini Sampath, Maya Krishnan, Srivatsa Kundurthy, Sean Hendryx, Zifan Wang, Chen Bo Calvin Zhang, Noah Jacobson, Bing Liu, Brad Kenstler._ arXiv 2025.  
  [![Paper](https://img.shields.io/badge/paper-A42C25?style=for-the-badge&logo=arxiv&logoColor=white)](https://arxiv.org/abs/2509.16941) [![GitHub Stars](https://img.shields.io/github/stars/scaleapi/SWE-bench_Pro-os?style=for-the-badge&logo=github&label=GitHub&color=black)](https://github.com/scaleapi/SWE-bench_Pro-os) [![Website](https://img.shields.io/website?url=https://scale.com/leaderboard/swe_bench_pro_public&up_message=SWE-BENCH-PRO-PUBLIC&up_color=blue&down_message=SWE-BENCH-PRO-PUBLIC&down_color=blue&style=for-the-badge)](https://scale.com/leaderboard/swe_bench_pro_public)

- **SWE-PolyBench: A multi-language benchmark for repository level evaluation of coding agents.**  
  _Muhammad Shihab Rashid, Christian Bock, Yuan Zhuang, Alexander Buchholz, Tim Esler, Simon Valentin, Luca Franceschi, Martin Wistuba, Prabhu Teja Sivaprasad, Woo Jung Kim, Anoop Deoras, Giovanni Zappella, Laurent Callot._ arXiv 2025.  
  [![Paper](https://img.shields.io/badge/paper-A42C25?style=for-the-badge&logo=arxiv&logoColor=white)](https://arxiv.org/abs/2504.08703) [![GitHub Stars](https://img.shields.io/github/stars/amazon-science/SWE-PolyBench?style=for-the-badge&logo=github&label=GitHub&color=black)](https://github.com/amazon-science/SWE-PolyBench) [![Website](https://img.shields.io/website?url=https://amazon-science.github.io/SWE-PolyBench/&up_message=SWE-POLYBENCH&up_color=blue&down_message=SWE-POLYBENCH&down_color=blue&style=for-the-badge)](https://amazon-science.github.io/SWE-PolyBench/)

- **Multi-SWE-bench: A Multilingual Benchmark for Issue Resolving.**  
  _Daoguang Zan, Zhirong Huang, Wei Liu, Hanwu Chen, Linhao Zhang, Shulin Xin, Lu Chen, Qi Liu, Xiaojian Zhong, Aoyan Li, Siyao Liu, Yongsheng Xiao, Liangqiang Chen, Yuyu Zhang, Jing Su, Tianyu Liu, Rui Long, Kai Shen, Liang Xiang._ arXiv 2025.  
  [![Paper](https://img.shields.io/badge/paper-A42C25?style=for-the-badge&logo=arxiv&logoColor=white)](https://arxiv.org/abs/2504.02605) [![GitHub Stars](https://img.shields.io/github/stars/multi-swe-bench/multi-swe-bench?style=for-the-badge&logo=github&label=GitHub&color=black)](https://github.com/multi-swe-bench/multi-swe-bench) [![Website](https://img.shields.io/website?url=https://multi-swe-bench.github.io/&up_message=MULTI-SWE-BENCH&up_color=blue&down_message=MULTI-SWE-BENCH&down_color=blue&style=for-the-badge)](https://multi-swe-bench.github.io/)

- **SWE-Effi: Re-Evaluating Software AI Agent System Effectiveness Under Resource Constraints.**  
  _Zhiyu Fan, Kirill Vasilevski, Dayi Lin, Boyuan Chen, Yihao Chen, Zhiqing Zhong, Jie M. Zhang, Pinjia He, Ahmed E. Hassan._ arXiv 2025.  
  [![Paper](https://img.shields.io/badge/paper-A42C25?style=for-the-badge&logo=arxiv&logoColor=white)](https://arxiv.org/abs/2509.09853) [![Website](https://img.shields.io/website?url=https://github.com/Centre-for-Software-Excellence/SWE-Effi&up_message=SWE-EFFI&up_color=blue&down_message=SWE-EFFI&down_color=blue&style=for-the-badge)](https://github.com/Centre-for-Software-Excellence/SWE-Effi)

- **Saving SWE-Bench: A Benchmark Mutation Approach for Realistic Agent Evaluation.**  
  _Spandan Garg, Ben Steenhoek, Yufan Huang._ arXiv 2025.  
  [![Paper](https://img.shields.io/badge/paper-A42C25?style=for-the-badge&logo=arxiv&logoColor=white)](https://arxiv.org/abs/2510.08996)

- **SWE-MERA: A Dynamic Benchmark for Agenticly Evaluating Large Language Models on Software Engineering Tasks.**  
  _Pavel Adamenko, Mikhail Ivanov, Aidar Valeev, Rodion Levichev, Pavel Zadorozhny, Ivan Lopatin, Dmitry Babayev, Alena Fenogenova, Valentin Malykh._ arXiv 2025.  
  [![Paper](https://img.shields.io/badge/paper-A42C25?style=for-the-badge&logo=arxiv&logoColor=white)](https://arxiv.org/abs/2507.11059) [![GitHub Stars](https://img.shields.io/github/stars/MERA-Evaluation/repotest?style=for-the-badge&logo=github&label=GitHub&color=black)](https://github.com/MERA-Evaluation/repotest) [![Website](https://img.shields.io/website?url=https://mera-evaluation.github.io/demo-swe-mera/&up_message=DEMO-SWE-MERA&up_color=blue&down_message=DEMO-SWE-MERA&down_color=blue&style=for-the-badge)](https://mera-evaluation.github.io/demo-swe-mera/)

- **Auto-SWE-Bench: A Framework for the Scalable Generation of Software Engineering Benchmark from Open-Source Repositories.**  
  _Anonymous Authors._ 2025.  
  [![Paper](https://img.shields.io/badge/paper-A42C25?style=for-the-badge&logo=arxiv&logoColor=white)](https://openreview.net/forum?id=Gxw1EDSm9S)

- **SWE-RL: Advancing LLM Reasoning via Reinforcement Learning on Open Software Evolution.**  
  _Yuxiang Wei, Olivier Duchenne, Jade Copet, Quentin Carbonneaux, Lingming Zhang, Daniel Fried, Gabriel Synnaeve, Rishabh Singh, Sida I. Wang._ NeurIPS 2025.  
  [![Paper](https://img.shields.io/badge/paper-A42C25?style=for-the-badge&logo=arxiv&logoColor=white)](https://arxiv.org/abs/2502.18449) [![GitHub Stars](https://img.shields.io/github/stars/facebookresearch/swe-rl?style=for-the-badge&logo=github&label=GitHub&color=black)](https://github.com/facebookresearch/swe-rl)

- **SWE-bench Goes Live!**  
  _Linghao Zhang, Shilin He, Chaoyun Zhang, Yu Kang, Bowen Li, Chengxing Xie, Junhao Wang, Maoquan Wang, Yufan Huang, Shengyu Fu, Elsie Nallipogu, Qingwei Lin, Yingnong Dang, Saravan Rajmohan, Dongmei Zhang._ NeurIPS 2025 Datasets & Benchmarks Track.  
  [![Paper](https://img.shields.io/badge/paper-A42C25?style=for-the-badge&logo=arxiv&logoColor=white)](https://arxiv.org/abs/2505.23419) [![GitHub Stars](https://img.shields.io/github/stars/microsoft/SWE-bench-Live?style=for-the-badge&logo=github&label=GitHub&color=black)](https://github.com/microsoft/SWE-bench-Live) [![Website](https://img.shields.io/website?url=https://swe-bench-live.github.io/&up_message=SWE-BENCH-LIVE&up_color=blue&down_message=SWE-BENCH-LIVE&down_color=blue&style=for-the-badge)](https://swe-bench-live.github.io/)

- **Training Software Engineering Agents and Verifiers with SWE-Gym.**  
  _Jiayi Pan, Xingyao Wang, Graham Neubig, Navdeep Jaitly, Heng Ji, Alane Suhr, Yizhe Zhang._ ICML 2025.  
  [![Paper](https://img.shields.io/badge/paper-A42C25?style=for-the-badge&logo=arxiv&logoColor=white)](https://arxiv.org/abs/2412.21139) [![GitHub Stars](https://img.shields.io/github/stars/SWE-Gym/SWE-Gym?style=for-the-badge&logo=github&label=GitHub&color=black)](https://github.com/SWE-Gym/SWE-Gym)

- **SWE-Lancer: Can Frontier LLMs Earn $1 Million from Real-World Freelance Software Engineering?**  
  _Samuel Miserendino, Michele Wang, Tejal Patwardhan, Johannes Heidecke._ ICML 2025.  
  [![Paper](https://img.shields.io/badge/paper-A42C25?style=for-the-badge&logo=arxiv&logoColor=white)](https://arxiv.org/abs/2502.12115) [![GitHub Stars](https://img.shields.io/github/stars/openai/frontier-evals?style=for-the-badge&logo=github&label=GitHub&color=black)](https://github.com/openai/frontier-evals/tree/main/project/swelancer) [![Website](https://img.shields.io/website?url=https://openai.com/index/swe-lancer/&up_message=SWE-LANCER&up_color=blue&down_message=SWE-LANCER&down_color=blue&style=for-the-badge)](https://openai.com/index/swe-lancer/)

- **SWE-GPT: A Process-Centric Language Model for Automated Software Improvement.**  
  _Yingwei Ma, Rongyu Cao, Yongchang Cao, Yue Zhang, Jue Chen, Yibo Liu, Yuchen Liu, Binhua Li, Fei Huang, Yongbin Li._ ISSTA 2025.  
  [![Paper](https://img.shields.io/badge/paper-A42C25?style=for-the-badge&logo=arxiv&logoColor=white)](https://arxiv.org/abs/2411.00622) [![GitHub Stars](https://img.shields.io/github/stars/LingmaTongyi/Lingma-SWE-GPT?style=for-the-badge&logo=github&label=GitHub&color=black)](https://github.com/LingmaTongyi/Lingma-SWE-GPT)

- **SWE-Fixer: Training Open-Source LLMs for Effective and Efficient GitHub Issue Resolution.**  
  _Chengxing Xie, Bowen Li, Chang Gao, He Du, Wai Lam, Difan Zou, Kai Chen._ ACL 2025 Findings.  
  [![Paper](https://img.shields.io/badge/paper-A42C25?style=for-the-badge&logo=arxiv&logoColor=white)](https://arxiv.org/abs/2501.05040) [![GitHub Stars](https://img.shields.io/github/stars/InternLM/SWE-Fixer?style=for-the-badge&logo=github&label=GitHub&color=black)](https://github.com/InternLM/SWE-Fixer)

- **OpenHands: An Open Platform for AI Software Developers as Generalist Agents.**  
  _Xingyao Wang, Boxuan Li, Yufan Song, Frank F. Xu, Xiangru Tang, Mingchen Zhuge, Jiayi Pan, Yueqi Song, Bowen Li, Jaskirat Singh, Hoang H. Tran, Fuqiang Li, Ren Ma, Mingzhang Zheng, Bill Qian, Yanjun Shao, Niklas Muennighoff, Yizhe Zhang, Binyuan Hui, Junyang Lin, Robert Brennan, Hao Peng, Heng Ji, Graham Neubig._ ICLR 2025.  
  [![Paper](https://img.shields.io/badge/paper-A42C25?style=for-the-badge&logo=arxiv&logoColor=white)](https://arxiv.org/abs/2407.16741) [![GitHub Stars](https://img.shields.io/github/stars/All-Hands-AI/OpenHands?style=for-the-badge&logo=github&label=GitHub&color=black)](https://github.com/All-Hands-AI/OpenHands) [![Website](https://img.shields.io/website?url=https://www.all-hands.dev/&up_message=ALL-HANDS&up_color=blue&down_message=ALL-HANDS&down_color=blue&style=for-the-badge)](https://www.all-hands.dev/)

- **Agentless: Demystifying LLM-based Software Engineering Agents.**  
  _Chunqiu Steven Xia, Yinlin Deng, Soren Dunn, Lingming Zhang._ FSE 2025.  
  [![Paper](https://img.shields.io/badge/paper-A42C25?style=for-the-badge&logo=arxiv&logoColor=white)](https://arxiv.org/abs/2407.01489) [![GitHub Stars](https://img.shields.io/github/stars/OpenAutoCoder/Agentless?style=for-the-badge&logo=github&label=GitHub&color=black)](https://github.com/OpenAutoCoder/Agentless)

- **OmniGIRL: A Multilingual and Multimodal Benchmark for GitHub Issue Resolution.**  
  _Lianghong Guo, Wei Tao, Runhan Jiang, Yanlin Wang, Jiachi Chen, Xilin Liu, Yuchi Ma, Mingzhi Mao, Hongyu Zhang, Zibin Zheng._ ISSTA 2025.  
  [![Paper](https://img.shields.io/badge/paper-A42C25?style=for-the-badge&logo=arxiv&logoColor=white)](https://arxiv.org/abs/2505.04606) [![GitHub Stars](https://img.shields.io/github/stars/DeepSoftwareAnalytics/OmniGIRL?style=for-the-badge&logo=github&label=GitHub&color=black)](https://github.com/DeepSoftwareAnalytics/OmniGIRL) [![Website](https://img.shields.io/website?url=https://deepsoftwareanalytics.github.io/omnigirl_leaderboard.html&up_message=OMNIGIRL-LEADERBOARD&up_color=blue&down_message=OMNIGIRL-LEADERBOARD&down_color=blue&style=for-the-badge)](https://deepsoftwareanalytics.github.io/omnigirl_leaderboard.html)

- **AutoCodeRover: Autonomous Program Improvement.**  
  _Yuntong Zhang, Haifeng Ruan, Zhiyu Fan, Abhik Roychoudhury._ ISSTA 2024.  
  [![Paper](https://img.shields.io/badge/paper-A42C25?style=for-the-badge&logo=arxiv&logoColor=white)](https://arxiv.org/abs/2404.05427) [![GitHub Stars](https://img.shields.io/github/stars/AutoCodeRoverSG/auto-code-rover?style=for-the-badge&logo=github&label=GitHub&color=black)](https://github.com/AutoCodeRoverSG/auto-code-rover) [![Website](https://img.shields.io/website?url=https://autocoderover.dev/&up_message=AUTOCODEROVER&up_color=blue&down_message=AUTOCODEROVER&down_color=blue&style=for-the-badge)](https://autocoderover.dev/)

- **SWE-agent: Agent-Computer Interfaces Enable Automated Software Engineering.**  
  _John Yang, Carlos E. Jimenez, Alexander Wettig, Kilian Lieret, Shunyu Yao, Karthik R. Narasimhan, Ofir Press._ NeurIPS 2024.  
  [![Paper](https://img.shields.io/badge/paper-A42C25?style=for-the-badge&logo=arxiv&logoColor=white)](https://arxiv.org/abs/2405.15793) [![GitHub Stars](https://img.shields.io/github/stars/SWE-agent/SWE-agent?style=for-the-badge&logo=github&label=GitHub&color=black)](https://github.com/SWE-agent/SWE-agent) [![Website](https://img.shields.io/website?url=https://swe-agent.com/&up_message=SWE-AGENT&up_color=blue&down_message=SWE-AGENT&down_color=blue&style=for-the-badge)](https://swe-agent.com/)

- **SWE-bench: Can Language Models Resolve Real-World GitHub Issues?**  
  _Carlos E. Jimenez, John Yang, Alexander Wettig, Shunyu Yao, Kexin Pei, Ofir Press, Karthik Narasimhan._ ICLR 2024.  
  [![Paper](https://img.shields.io/badge/paper-A42C25?style=for-the-badge&logo=arxiv&logoColor=white)](https://arxiv.org/abs/2310.06770) [![GitHub Stars](https://img.shields.io/github/stars/SWE-bench/SWE-bench?style=for-the-badge&logo=github&label=GitHub&color=black)](https://github.com/SWE-bench/SWE-bench) [![Website](https://img.shields.io/website?url=https://www.swebench.com/&up_message=SWEBENCH&up_color=blue&down_message=SWEBENCH&down_color=blue&style=for-the-badge)](https://www.swebench.com/)
<!-- END PAPERS:issue_resolution -->

- **SWE-agent: Agent-Computer Interfaces Enable Automated Software Engineering.** _John Yang, Carlos E. Jimenez, Alexander Wettig, Kilian Lieret, Shunyu Yao, Karthik Narasimhan, Ofir Press._ NeurIPS 2024.<br>[![Paper](https://img.shields.io/badge/paper-A42C25?style=for-the-badge&logo=arxiv&logoColor=white)](https://arxiv.org/abs/2405.15793) [![GitHub Stars](https://img.shields.io/github/stars/SWE-agent/SWE-agent?style=for-the-badge&logo=github&label=GitHub&color=black)](https://github.com/SWE-agent/SWE-agent)

- debug-gym: A Text-Based Environment for Interactive Debugging
- SemAgent: A Semantics-Aware Program Repair Agent
- CodeR: Issue Resolving with Multi-Agent and Task Graphs
- Code Graph Model (CGM): A Graph-Integrated Large Language Model for Repository-Level Software Engineering Tasks
- SWE-Exp: Experience-Driven Software Issue Resolution
- SE-Agent: Self-Evolution Trajectory Optimization in Multi-Step Reasoning with LLM-Based Agents
- SWE-Debate: Competitive Multi-Agent Debate for Software Issue Resolution
- Co-PatcheR: Collaborative Software Patching with Component(s)-specific Small Reasoning Models
- A Self-Improving Coding Agent
- SWE-Bench-CL: Continual Learning for Coding Agents
- Trae Agent: An LLM-based Agent for Software Engineering with Test-time Scaling
- SoRFT: Issue Resolving with Subtask-oriented Reinforced Fine-Tuning
- Co-Evolving LLM Coder and Unit Tester via Reinforcement Learning

---

### ðŸ§‘â€ðŸ’» Agentic Code Generation
> AI agents that autonomously generate, scaffold, and synthesize code at the repository level, leveraging external tools and APIs to create new modules, build complete projects, and construct large-scale codebases.

<!-- START PAPERS:code_generation -->

<!-- END PAPERS:code_generation -->

---

### ðŸ— Environment Building
> Papers describing new environments, IDE sandboxes, benchmarks, or agent playgrounds.

<!-- START PAPERS:environment_building -->
- **EnvBench: A Benchmark for Automated Environment Setup.**  
  _Aleksandra Eliseeva, Alexander Kovrigin, Ilia Kholkin, Egor Bogomolov, Yaroslav Zharov._ ICLR 2025 Workshop.  
  [![Paper](https://img.shields.io/badge/paper-A42C25?style=for-the-badge&logo=arxiv&logoColor=white)](https://arxiv.org/abs/2503.14443) [![GitHub Stars](https://img.shields.io/github/stars/JetBrains-Research/EnvBench?style=for-the-badge&logo=github&label=GitHub&color=black)](https://github.com/JetBrains-Research/EnvBench) [![Website](https://img.shields.io/website?url=https://huggingface.co/datasets/JetBrains-Research/EnvBench&up_message=ENVBENCH&up_color=blue&down_message=ENVBENCH&down_color=blue&style=for-the-badge)](https://huggingface.co/datasets/JetBrains-Research/EnvBench)
<!-- END PAPERS:environment_building -->

- R2E: Turning any Github Repository into a Programming Agent Environment
- R2E-Gym: Procedural Environment Generation and Hybrid Verifiers for Scaling Open-Weights SWE Agents
- RepoST: Scalable Repository-Level Coding Environment Construction with Sandbox Testing
- You Name It, I Run It: An LLM Agent to Execute Tests of Arbitrary Projects
- Automated Benchmark Generation for Repository-Level Coding Tasks
- Treefix: Enabling Execution with a Tree of Prefixes
- CompileAgent: Automated Real-World Repo-Level Compilation with Tool-Integrated LLM-based Agent System
- AutoDev: Automated AI-Driven Development
- CXXCrafter: An LLM-Based Agent for Automated C/C++ Open Source Software Building
- CSR-Bench: Benchmarking LLM Agents in Deployment of Computer Science Research Repositories
- Automatically Generating Dockerfiles via Deep Learning: Challenges and Promises
- Beyond pip Install: Evaluating LLM Agents for the Automated Installation of Python Projects
- Repo2Run: Automated Building Executable Environment for Code Repository at Scale

---

### ðŸ” Issue Reproduction
> Research on reproducing software bugs deterministically.

- Issue2Test: Generating Reproducing Test Cases from Issue Reports

---

### ðŸŽ¯ Issue Localization
> Code search, fault localization, vulnerability detection.
- LocAgent: Graph-Guided LLM Agents for Code Localization
- ToolTrain: Tool-integrated Reinforcement Learning for Repo Deep Search

<!-- START PAPERS:issue_localization -->
- **Issue Localization via LLM-Driven Iterative Code Graph Searching.**  
  _Zhonghao Jiang, Xiaoxue Ren, Meng Yan, Wei Jiang, Yong Li, Zhongxin Liu._ ASE 2025.  
  [![Paper](https://img.shields.io/badge/paper-A42C25?style=for-the-badge&logo=arxiv&logoColor=white)](https://arxiv.org/abs/2503.22424) [![GitHub Stars](https://img.shields.io/github/stars/ZhonghaoJiang/CoSIL?style=for-the-badge&logo=github&label=GitHub&color=black)](https://github.com/ZhonghaoJiang/CoSIL)
<!-- END PAPERS:issue_localization -->

---

### â“ Q&A
> Code understanding, documentation, and retrieval-based Q&A.

- SWE-QA: Can Language Models Answer Repository-level Code Questions?

---

### ðŸ” Pull Request Review
> Automated pull request creation, review assistance, linting, refactoring.  

<!-- START PAPERS:pull_request_review -->
- **PReview: A Benchmark Dataset for Pull Request Outcomes and Quality Analysis.**  
  _Anonymous Authors._ 2025.  
  [![Paper](https://img.shields.io/badge/paper-A42C25?style=for-the-badge&logo=arxiv&logoColor=white)](https://openreview.net/forum?id=cdwp8BXTVV)

- **PR-Agent: An AI-Powered Tool for Automated Pull Request Analysis, Feedback, Suggestions and More!**  
  _Qodo._ 2024.  
  [![GitHub Stars](https://img.shields.io/github/stars/qodo-ai/pr-agent?style=for-the-badge&logo=github&label=GitHub&color=black)](https://github.com/qodo-ai/pr-agent) [![Website](https://img.shields.io/website?url=https://www.qodo.ai/&up_message=QODO.AI&up_color=blue&down_message=QODO.AI&down_color=blue&style=for-the-badge)](https://www.qodo.ai/)
<!-- END PAPERS:pull_request_review -->

---

### âœ¨ Feature Development
> Studies on agent-driven feature extension, repo-level edits.

<!-- START PAPERS:feature_development -->
- **FEA-Bench: A Benchmark for Evaluating Repository-Level Code Generation for Feature Implementation.**  
  _Wei Li, Xin Zhang, Zhongxin Guo, Shaoguang Mao, Wen Luo, Guangyue Peng, Yangyu Huang, Houfeng Wang, Scarlett Li._ ACL 2025.  
  [![Paper](https://img.shields.io/badge/paper-A42C25?style=for-the-badge&logo=arxiv&logoColor=white)](https://arxiv.org/abs/2503.06680) [![GitHub Stars](https://img.shields.io/github/stars/microsoft/FEA-Bench?style=for-the-badge&logo=github&label=GitHub&color=black)](https://github.com/microsoft/FEA-Bench) [![Website](https://img.shields.io/website?url=https://gmago-leway.github.io/fea-bench.github.io/&up_message=FEA-BENCH.GITHUB.IO&up_color=blue&down_message=FEA-BENCH.GITHUB.IO&down_color=blue&style=for-the-badge)](https://gmago-leway.github.io/fea-bench.github.io/)
<!-- END PAPERS:feature_development -->

- SWE-Dev: Evaluating and Training Autonomous Feature-Driven Software Development
- NoCode-bench: A Benchmark for Evaluating Natural Language-Driven Feature Addition

---

### ðŸ”„ Git Management
> Agents for git workflows (branching, rebasing, conflict resolution).  

- GitGoodBench: A Novel Benchmark For Evaluating Agentic Performance On Git

---

### âš¡ Performance Optimization
> Code profiling, optimization, memory & latency improvements.

- SWE-Perf: Can Language Models Optimize Code Performance on Real-World Repositories?

---

### ðŸŒ Website Generation
> Code agents that generate or maintain websites/frontends.

- WebGen-Bench: Evaluating LLMs on Generating Interactive and Functional Websites from Scratch
- ScreenCoder: Advancing Visual-to-Code Generation for Front-End Automation via Modular Multimodal Agents

---

### ðŸ‘©â€ðŸ’» Machine Learning Engineering
> Autonomous agents across end-to-end ML workflows.

<!-- START PAPERS:machine_learning_engineering -->
- **MLE-bench: Evaluating Machine Learning Agents on Machine Learning Engineering.**  
  _Jun Shern Chan, Neil Chowdhury, Oliver Jaffe, James Aung, Dane Sherburn, Evan Mays, Giulio Starace, Kevin Liu, Leon Maksin, Tejal Patwardhan, Lilian Weng, Aleksander MÄ…dry._ ICLR 2025.  
  [![Paper](https://img.shields.io/badge/paper-A42C25?style=for-the-badge&logo=arxiv&logoColor=white)](https://arxiv.org/abs/2410.07095) [![GitHub Stars](https://img.shields.io/github/stars/openai/mle-bench?style=for-the-badge&logo=github&label=GitHub&color=black)](https://github.com/openai/mle-bench) [![Website](https://img.shields.io/website?url=https://openai.com/index/mle-bench/&up_message=MLE-BENCH&up_color=blue&down_message=MLE-BENCH&down_color=blue&style=for-the-badge)](https://openai.com/index/mle-bench/)
<!-- END PAPERS:machine_learning_engineering -->

---

### Automated Data Science
> 

<!-- START PAPERS:automated_data_science -->
- **AutoMind: Adaptive Knowledgeable Agent for Automated Data Science.**  
  _Yixin Ou, Yujie Luo, Jingsheng Zheng, Lanning Wei, Zhuoyun Yu, Shuofei Qiao, Jintian Zhang, Da Zheng, Yuren Mao, Yunjun Gao, Huajun Chen, Ningyu Zhang._ arXiv 2025.  
  [![Paper](https://img.shields.io/badge/paper-A42C25?style=for-the-badge&logo=arxiv&logoColor=white)](https://arxiv.org/abs/2506.10974) [![GitHub Stars](https://img.shields.io/github/stars/innovatingAI/AutoMind?style=for-the-badge&logo=github&label=GitHub&color=black)](https://github.com/innovatingAI/AutoMind) [![Website](https://img.shields.io/website?url=https://innovatingai.github.io/&up_message=INNOVATINGAI&up_color=blue&down_message=INNOVATINGAI&down_color=blue&style=for-the-badge)](https://innovatingai.github.io/)
<!-- END PAPERS:automated_data_science -->

---

### ðŸ”’ Software Security Engineering
> Studies on agentic vulnerability detection, patching, and secure coding.

<!-- START PAPERS:software_security_engineering -->

<!-- END PAPERS:software_security_engineering -->

---

### SQL Engineering
>  Autonomous agents for solving SQL challenges in real-world database systems (_e.g_., query generation and optimization, issue resolution).

<!-- START PAPERS:sql_engineering -->
- **SWE-SQL: Illuminating LLM Pathways to Solve User SQL Issues in Real-World Applications.**  
  _Jinyang Li, Xiaolong Li, Ge Qu, Per Jacobsson, Bowen Qin, Binyuan Hui, Shuzheng Si, Nan Huo, Xiaohan Xu, Yue Zhang, Ziwei Tang, Yuanshuai Li, Florensia Widjaja, Xintong Zhu, Feige Zhou, Yongfeng Huang, Yannis Papakonstantinou, Fatma Ozcan, Chenhao Ma, Reynold Cheng._ arXiv 2025.  
  [![Paper](https://img.shields.io/badge/paper-A42C25?style=for-the-badge&logo=arxiv&logoColor=white)](https://arxiv.org/abs/2506.18951) [![GitHub Stars](https://img.shields.io/github/stars/bird-bench/BIRD-CRITIC-1?style=for-the-badge&logo=github&label=GitHub&color=black)](https://github.com/bird-bench/BIRD-CRITIC-1) [![Website](https://img.shields.io/website?url=https://bird-critic.github.io/&up_message=BIRD-CRITIC&up_color=blue&down_message=BIRD-CRITIC&down_color=blue&style=for-the-badge)](https://bird-critic.github.io/)
<!-- END PAPERS:sql_engineering -->

---

### ðŸ•¹ï¸ Unified Agents
> Unified Software Engineering agent as AI Software Engineer

---

### ðŸŽ“ Post-Training
> Instruction tuning, alignment, reinforcement learning for SWE agents.

- Training Software Engineering Agents and Verifiers with SWE-Gym
- SEAlign: Alignment Training for Software Engineering Agent
- Agent-RLVR: Training Software Engineering Agents via Guidance and Environment Rewards

---

### âš– Test-time Scaling
> Chain-of-thought, self-reflection, scaling strategies during inference.  

- SWE-Search: Enhancing Software Agents with Monte Carlo Tree Search and Iterative Refinement
- Thinking Longer, Not Larger: Enhancing Software Engineering Agents via Scaling Test-Time Compute

---

### ðŸ–¼ Multimodal
> Agents that leverage images/screenshots/GUI for coding tasks.

- Seeing is Fixing: Cross-Modal Reasoning with Multimodal LLMs for Visual Software Issue Fixing

---

### ðŸ§¬ Data Synthesis
> Synthetic data generation for code tasks, self-play, augmentation.

- MCTS-Refined CoT: High-Quality Fine-Tuning Data for LLM-Based Repository Issue Resolution
- SWE-Flow: Synthesizing Software Engineering Data in a Test-Driven Manner
- SWE-Factory: Your Automated Factory for Issue Resolution Training Data and Evaluation Benchmarks
- SPICE: An Automated SWE-Bench Labeling Pipeline for Issue Clarity, Test Coverage, and Effort Estimation

---

### ðŸ“Š Empirical Studies
> Evaluations of LLMs/agents on large-scale software repositories. Analysis of failure cases, bias, reproducibility.  

- Understanding Software Engineering Agents Through the Lens of Traceability: An Empirical Study
- Can LLMs Replace Manual Annotation of Software Engineering Artifacts?
- Understanding Software Engineering Agents: A Study of Thought-Action-Result Trajectories

---

## ðŸ¤ Contributing
We welcome contributions! Please:  
1. Use the [entry template](#entry-template).  
2. Place items in the right category & order by **reverse-chronology**.  
3. Include badges for GitHub stars, arXiv, website if available.

We're grateful to all our amazing contributors who have made this project what it is today!

<a href="https://github.com/EuniAI/awesome-code-agents/graphs/contributors">
  <img src="https://contrib.rocks/image?repo=EuniAI/awesome-code-agents&r="  width="80px"/>
</a>

If you have any questions or encounter issues, please feel free to reach out. For quick queries, you can also check our `Issues` page for common questions and solutions.

---

## ðŸŒŸ Star History
[![Star History Chart](https://api.star-history.com/svg?repos=EuniAI/awesome-code-agents&type=Date)](https://www.star-history.com/#EuniAI/awesome-code-agents&Date)

---

## ðŸ™ Acknowledgements
- Thanks to all contributors and the research community.
